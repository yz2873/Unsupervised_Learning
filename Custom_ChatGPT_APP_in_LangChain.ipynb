{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/waIzT1J7UNbdcCpqZX2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yz2873/Unsupervised_Learning/blob/master/Custom_ChatGPT_APP_in_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Custom ChatGPT App in langchain and using langchain.memory.ConversionBufferMemory to continuse talking**"
      ],
      "metadata": {
        "id": "tw0zEzxWjFLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3AbhN8vi6vc",
        "outputId": "224e7408-9647-4fca-f488-db32bc3c836c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDRW8oAStyBr",
        "outputId": "a195b850-05b5-4c53-979a-2a63267d8a9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.33-py3-none-any.whl (47 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
            "Installing collected packages: fastavro, backoff, cohere\n",
            "Successfully installed backoff-2.2.1 cohere-4.33 fastavro-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "KbUrXaDfeDGx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf4Sh8jpKNg4",
        "outputId": "38f9304c-716a-4a11-9e38-3bedddd88795"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.2.0\n",
            "Summary: Client library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, tqdm, typing-extensions\n",
            "Required-by: llmx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaHl2lyfKvl6",
        "outputId": "8721293c-0289-44f1-a718-ea8a905851f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e4GppCjfSwa",
        "outputId": "3b855202-6757-4055-9a1f-5f15d5e06697"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.332\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the API Keys**"
      ],
      "metadata": {
        "id": "kloPe-nGffJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "WUcBBP6-fmMJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhaZn8fsgFJY",
        "outputId": "d7ec7c22-f557-4df8-8ec3-5df9c7e9498f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('/content/drive/My Drive/.env', override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmJYTDjggVUL",
        "outputId": "5c4479cb-6c58-4b1b-f019-b8817cc4bca5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "NcgsdIQmgbht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "4j-mLYLGMR7J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)"
      ],
      "metadata": {
        "id": "b31B_xtnhHSD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
      ],
      "metadata": {
        "id": "PghhxyHKhRmQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate(\n",
        "    input_variables= ['content'],\n",
        "    messages= [\n",
        "        SystemMessage(content='You are a chatbot having a conversion with a human.'),\n",
        "        MessagesPlaceholder(variable_name='chat_history'),\n",
        "        HumanMessagePromptTemplate.from_template('{content}')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "XNe7IJkXhhwq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = prompt,\n",
        "    memory=memory,\n",
        "    verbose = False\n",
        ")"
      ],
      "metadata": {
        "id": "LfWXOnzphucH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    content = input(\"Your Prompt: \")\n",
        "    if content in ['quit', 'exit', 'bye']:\n",
        "        print('GoodBye...')\n",
        "        break\n",
        "\n",
        "    response = chain.run({'content': content})\n",
        "    print(response)\n",
        "    print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIdv16-0iBFd",
        "outputId": "77e27b54-df16-4692-ec22-70b41395c9aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Prompt: Earth is ...\n",
            "Earth is a planet in the Solar System, the third planet from the Sun. It is the largest and densest of the four terrestrial planets, and the only known celestial body where life exists. It has a diverse environment, including oceans, landmasses, and an atmosphere that supports a wide variety of ecosystems and living organisms. Earth is also the home to billions of humans, as well as countless other species of plants and animals.\n",
            "--------------------------------------------------\n",
            "Your Prompt: its diameter is ...\n",
            "The diameter of Earth is approximately 12,742 kilometers (7,918 miles) at the equator. This measurement represents the widest point of the planet when measured from one side to the other through its center. It is important to note that Earth is not a perfect sphere, but rather slightly flattened at the poles and bulging at the equator due to its rotation.\n",
            "--------------------------------------------------\n",
            "Your Prompt: what questions did I ask?\n",
            "You asked two questions:\n",
            "1. \"Earth is...\"\n",
            "2. \"Its diameter is...\"\n",
            "--------------------------------------------------\n",
            "Your Prompt: quit\n",
            "GoodBye...\n"
          ]
        }
      ]
    }
  ]
}