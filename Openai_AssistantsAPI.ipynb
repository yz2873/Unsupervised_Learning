{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNMmql40aj9Gh2kgJVOVbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yz2873/Unsupervised_Learning/blob/master/Openai_AssistantsAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install All Modules**"
      ],
      "metadata": {
        "id": "5ihu49Ybz_A6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCPPkjC-svnp",
        "outputId": "100e6ff3-a0d8-4954-fb8c-03477746fc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.37-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.3.9-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Installing collected packages: importlib_metadata, h11, fastavro, backoff, tiktoken, httpcore, httpx, cohere, openai\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "Successfully installed backoff-2.2.1 cohere-4.37 fastavro-1.9.1 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 importlib_metadata-6.11.0 openai-1.3.9 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade cohere tiktoken openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCLZoNIAtH4y",
        "outputId": "1c736117-2d4e-432c-a219-ad0989a4d829"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.3.9\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: llmx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08CDiORrtoAZ",
        "outputId": "e6a98939-dcd1-437a-a27d-52afb12b6185"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load OpenAI API Key**"
      ],
      "metadata": {
        "id": "74an2x3J0NXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import find_dotenv, load_dotenv"
      ],
      "metadata": {
        "id": "PPRii9zhtWMn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWKio3pqtvzb",
        "outputId": "883ae0b3-bfcb-4dfd-e736-82fbd8c8674b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('/content/drive/My Drive/.env', override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB3Q03iPuFZT",
        "outputId": "e58443bd-af81-4b45-94b1-8c8f9d3fdac1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = os.environ.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "QhMiAaPUuGS2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "26WQYXksu_Ww"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "I7FfU6zgukEs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uploaded File**"
      ],
      "metadata": {
        "id": "piqf7UWCz1T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls FutureSmart_AI_NLP_GPT-3_ChatGPT_SemanticSearch.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCttePkUxRZV",
        "outputId": "ec8a5976-2f58-4123-85e7-5b683595ac6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FutureSmart_AI_NLP_GPT-3_ChatGPT_SemanticSearch.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kJzsY-4wz8Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = client.files.create(\n",
        "    file=open(\"FutureSmart_AI_NLP_GPT-3_ChatGPT_SemanticSearch.html\", 'rb'),\n",
        "    purpose='assistants',\n",
        ")"
      ],
      "metadata": {
        "id": "CMRXwU6Uyl6K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsnyMB81zfWQ",
        "outputId": "744d4a5a-46e7-452b-db2b-c926f47e5879"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-uScF8sX2rgHLdRjmjaOSpAjY', bytes=2465709, created_at=1702434454, filename='FutureSmart_AI_NLP_GPT-3_ChatGPT_SemanticSearch.html', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IPjU1bYzAKor",
        "outputId": "f23e3d3a-fbad-4477-b228-6b7250d94864"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-uScF8sX2rgHLdRjmjaOSpAjY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creation of Asistants**"
      ],
      "metadata": {
        "id": "HKRLR0sS0gdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Futuresmart AI Assistent\",\n",
        "    instructions=\"You are a AI Assistent that answers any queries related to Futuresmart AI\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=\"gpt-4-1106-preview\",   # This model I cannot access\n",
        "    file_ids=[uploaded.id]\n",
        ")"
      ],
      "metadata": {
        "id": "90_P6ijq0lbS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Thread**"
      ],
      "metadata": {
        "id": "AuZmU4YfD2SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The thread is communication\n",
        "thread = client.beta.threads.create()\n",
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyrdVM6AD7dM",
        "outputId": "4be9c7a5-5e6f-4a89-b01e-1e561e904577"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_qZZThzfi7SoOZLLoewTRns6D', created_at=1702435582, metadata={}, object='thread')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oNQJJlQYE6YE",
        "outputId": "5a5e3f59-3b11-4cb4-960d-a104d989f46e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thread_qZZThzfi7SoOZLLoewTRns6D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is Futuresmart AI?\n",
        "# What services does it offer?"
      ],
      "metadata": {
        "id": "uDlwAtOAEYiw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Message for thread**"
      ],
      "metadata": {
        "id": "ykNBbltVGUUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id = thread.id,\n",
        "    role = 'user',\n",
        "    content = 'What is Futuresmart AI?'\n",
        ")"
      ],
      "metadata": {
        "id": "8wXFCWCRE-Wv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.beta.threads.messages.list(thread_id=thread.id).data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92nU2t8PF7jG",
        "outputId": "1b8c8c9a-0420-4fc3-89d7-f4142e7d9c03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ThreadMessage(id='msg_uF14OItac0k2CLsy4VuhFPZb', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is Futuresmart AI?'), type='text')], created_at=1702435987, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_qZZThzfi7SoOZLLoewTRns6D')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run Assistant**"
      ],
      "metadata": {
        "id": "muC4TLCaGb1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/assistants/overview\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")"
      ],
      "metadata": {
        "id": "mVjOa3uNGiRS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "  if run.status == 'completed':\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    latest_message = messages.data[0]\n",
        "    text = latest_message.content[0].text.value\n",
        "    print(text)\n",
        "    break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCdyqPGPIoEQ",
        "outputId": "0c88e982-d806-4ed3-a1db-c691162ba700"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FutureSmart AI specializes in providing \"Custom Natural Language Processing Solutions\" and seems to position itself as a way for companies to adapt to a changing world and grow their business【9†source】.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Second Question: \"What services does it offer?\""
      ],
      "metadata": {
        "id": "3RfdUUtJLFyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id = thread.id,\n",
        "    role = 'user',\n",
        "    content = 'What services does it offer?'\n",
        ")"
      ],
      "metadata": {
        "id": "w575LSMALGgR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.beta.threads.messages.list(thread_id=thread.id).data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYV3IlDGLaGc",
        "outputId": "f5da5aab-9706-4f41-ffc5-173b407329de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ThreadMessage(id='msg_Ze1fQ2DpCXgHj2xT6TERnZav', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What services does it offer?'), type='text')], created_at=1702437430, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_qZZThzfi7SoOZLLoewTRns6D'),\n",
              " ThreadMessage(id='msg_F5E5waxeydXWQr1VClPnEJy0', assistant_id='asst_8y0eI9zIm89V94qQfjcMxVdi', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=201, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-uScF8sX2rgHLdRjmjaOSpAjY', quote='Custom Natural Language Processing Solutions _ NLP _ GPT-3 _ ChatGPT _ Semantic Search._files/b4164bf0-2d98-4385-a759-4fb06f4cfc50.png\" alt=\"FutureSmart AI\" style=\"width: 12rem;\"></a><div class=\"MuiStack-root css-zck3tn\"><div style=\"display: flex; align-items: center;\"><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium css-1y6x1ru\" tabindex=\"0\" data-element=\"button\" target=\"\" href=\"https://www.futuresmart.ai/\" style=\"height: fit-content;\"><span class=\"MuiBox-root css-jf8tht\">Home</span><span class=\"MuiTouchRipple-root css-w0pj6f\"></span></a><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium css-1y6x1ru\" tabindex=\"0\" data-element=\"button\" target=\"\" href=\"https://www.futuresmart.ai/#form2\" style=\"height: fit-content;\"><span class=\"MuiBox-root css-jf8tht\">Contact Us</span><span class=\"MuiTouchRipple-root css-w0pj6f\"></span></a><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium css-94du21\" tabindex=\"0\" data-element=\"button\" target=\"\" href=\"https://www.futuresmart.ai/services\" style=\"height: fit-content;\"><span class=\"MuiBox-root css-jf8tht\">Services</span><span class=\"MuiTouchRipple-root css-w0pj6f\"></span></a><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium css-94du21\" tabindex=\"0\" data-element=\"button\" target=\"_blank\" href=\"https://blog.futuresmart.ai/\" style=\"height: fit-content;\"><span class=\"MuiBox-root css-jf8tht\">Blog</span><span class=\"MuiTouchRipple-root css-w0pj6f\"></span></a><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeMedium MuiButton-containedSizeMedium css-94du21\" tabindex=\"0\" data-element=\"button\" target=\"_blank\" href=\"https://www.aidemos.com/\" style=\"height: fit-content;\"><span class=\"MuiBox-root css-jf8tht\">AI Demos</span><span class=\"MuiTouchRipple-root css-w0pj6f\"></span></a></div></div></div></div></header></div><header id=\"hero1\" style=\"\" class=\"hero1-533b605d-3383-445f-9d76-e96efb1c28e1 sw-background-color-4263eb sw-padding-top-xl sw-padding-bottom-xl sw-border-top-style-solid sw-border-top-width-xs sw-border-top-color-000000 sw-border-bottom-style-none sw-border-bottom-width-xs sw-border-bottom-color-000000  sw-background-repeat-no-repeat sw-background-size-cover sw-background-position-center sw-background-attachment-scroll \"><div class=\"container\"><div class=\"row align-items-center\"><div class=\"col-lg-6 pb-5 pb-lg-0 text-center text-lg-left\"><h1 class=\"sw-font-size-5xl sw-text-color-ffffff sw-font-family-default sw-font-weight-default sw-padding-top-none sw-padding-bottom-5xs sw-letter-spacing-normal sw-line-height-normal \">Custom Natural Language Processing Solutions</h1><p class=\"sw-font-size-xl sw-text-color-ffffff sw-font-family-default sw-font-weight-default sw-padding-top-none sw-padding-bottom-5xs sw-letter-spacing-normal sw-line-height-loose \">The world is changing, and so should you. Grow your company with FutureSmart AI'), start_index=191, text='【9†source】', type='file_citation')], value='FutureSmart AI specializes in providing \"Custom Natural Language Processing Solutions\" and seems to position itself as a way for companies to adapt to a changing world and grow their business【9†source】.'), type='text')], created_at=1702437017, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_ocEOVt0bLocjo6hBpXdmyK8Y', thread_id='thread_qZZThzfi7SoOZLLoewTRns6D'),\n",
              " ThreadMessage(id='msg_uF14OItac0k2CLsy4VuhFPZb', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is Futuresmart AI?'), type='text')], created_at=1702435987, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_qZZThzfi7SoOZLLoewTRns6D')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")"
      ],
      "metadata": {
        "id": "Hco5ZnR5L2SI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "  if run.status == 'completed':\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    latest_message = messages.data[0]\n",
        "    text = latest_message.content[0].text.value\n",
        "    print(text)\n",
        "    break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zugdn1bMD5c",
        "outputId": "81824005-582c-4ece-e193-8f14e98bbcd1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FutureSmart AI offers services that are focused on custom Natural Language Processing (NLP) solutions. Their services include:\n",
            "\n",
            "1. **Text Classification**: Helping companies sort and categorize documents automatically according to specific needs, saving time and ensuring proper document management.\n",
            "2. **Aspect-Based Sentiment Analysis**: Analyzing text sentiment related to particular aspects to understand customer feelings about products or services.\n",
            "3. **Named Entity Recognition**: Automatically extracting named entities like people, locations, organizations, and product names from text, with the development of custom models for entities specific to a domain or industry.\n",
            "4. **Chatbot Development**: Presumably, they offer services to design and deploy conversational agents or chatbots for varying use cases.\n",
            "\n",
            "Their dedicated team of Data Scientists and Machine Learning Engineers provides end-to-end solutions that encompass everything from data labeling to modeling and deploying machine learning models that are tailored to the specific use cases of clients【15†source】.\n"
          ]
        }
      ]
    }
  ]
}