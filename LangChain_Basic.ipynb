{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12qPKEyeFJJSF75nxZqtabU4HfKvs-s1H",
      "authorship_tag": "ABX9TyNMQ0f/Oqxn3wJuz9qkHJoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yz2873/Unsupervised_Learning/blob/master/LangChain_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain Basics**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9Q0jIlxJfFGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfFF-8arbdaz",
        "outputId": "c15e70fc-c3b0-4e15-c8fb-d8ca86cf8cd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "9DcPCMJrdKLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e3a838-7fcd-4504-a8c3-59dc7fb25854"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyNU3AJtdb4E",
        "outputId": "b58fd65d-9527-4d89-91a6-05fed2c01905"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.296\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the API Keys**"
      ],
      "metadata": {
        "id": "sHK0QHK3gnGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "R4p3bjqnd0dK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv(find_dotenv(), override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmyHD_yseSvp",
        "outputId": "b534fba6-bc6b-442c-9a4b-b26e9fb2c2b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = os.environ.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "-KH3AhTue4q6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Model GPT-3"
      ],
      "metadata": {
        "id": "8_9g-Bp7hFvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "GYdMiUcigien"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
        "print(llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rW8WR6WibQa",
        "outputId": "6b0a8bec-8093-4ddc-fc4e-14aadea6e598"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mOpenAI\u001b[0m\n",
            "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm('explain quantum mechanics in one sentance')\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4B-Yxgmjl5B",
        "outputId": "031cc01c-f19a-46c8-a750-5b45b71b5b1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Quantum mechanics is a branch of physics that explains the behavior of matter and energy at the atomic and subatomic level.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.get_num_tokens('explain quantum mechanics in one sentance'))"
      ],
      "metadata": {
        "id": "G1L0qrq7jq7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f72e021-a1c8-4305-ff28-ddd7129b346e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.generate(['... is capital of China', 'What is the formula for area of a circle'])"
      ],
      "metadata": {
        "id": "bZOGoyRjEOKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAXWMXvyFPXf",
        "outputId": "1b691588-f407-4963-dec0-6ea356a42bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n\\nBeijing is the capital of China.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='?\\n\\nThe formula for the area of a circle is A = πr^2, where r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 14, 'total_tokens': 53}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('0d4d2bc8-0fd8-42c9-ba08-08e7d3a915fd')), RunInfo(run_id=UUID('78e362f4-6eea-47e2-aecb-2191cf18f217'))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.generations[0][0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTrfEx4-Ff0V",
        "outputId": "728c8a89-4f4a-489b-f572-7d77e43952ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Beijing is the capital of China.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.generations[1][0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQMRwxY0FntB",
        "outputId": "cf414e02-8aa1-4c5a-91aa-d0abd31f0851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?\n",
            "\n",
            "The formula for the area of a circle is A = πr^2, where r is the radius of the circle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ChatModel: GPT-3.5-Turbo and GPT-4 (2023-08-16)**"
      ],
      "metadata": {
        "id": "qJhkqNPZLFGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "Zk9C-_lAGIQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)"
      ],
      "metadata": {
        "id": "NqIU8kfpM043"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content='You are a physicist and response only in Chinese.'),\n",
        "    HumanMessage(content='explain quantum mechanics in one sentance.')\n",
        "]"
      ],
      "metadata": {
        "id": "uzugI6aoOsE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqsR49koP1uZ",
        "outputId": "807b6d3d-473d-4f78-8dcf-0ed81e8034be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a physicist and response only in Chinese.', additional_kwargs={}),\n",
              " HumanMessage(content='explain quantum mechanics in one sentance.', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat(messages)"
      ],
      "metadata": {
        "id": "gbCHgNzoP4BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufltj2P3QQz6",
        "outputId": "f59c5fbd-bc32-4e4d-c134-c18ce5b5df8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "量子力学是一种描述微观粒子行为的物理理论，它通过波粒二象性、不确定性原理和量子叠加等概念来解释微观世界的奇特现象。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt Templates**"
      ],
      "metadata": {
        "id": "06s-HJU7RCtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "SD6nux01QUoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = ''' You are an experienced virologist.\n",
        "Write a few sentances about the following {virus} in {language}.'''\n",
        "template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNrcHzWcSPnb",
        "outputId": "c3d250f7-6a96-4fd1-c190-3133361c7e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' You are an experienced virologist. \\nWrite a few sentances about the following {virus} in {language}.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables = ['virus', 'language'], template= template)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTnmTRyQUcol",
        "outputId": "4c52c351-e0a4-4454-f1bd-b988ddb2511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['virus', 'language'] output_parser=None partial_variables={} template=' You are an experienced virologist. \\nWrite a few sentances about the following {virus} in {language}.' template_format='f-string' validate_template=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "2AjjIoksVsO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
        "output = llm(prompt.format(virus='ebola', language='chinese'))\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZFS7jyXVuPL",
        "outputId": "1a670e5f-ec31-4bea-fba6-0b386ff84af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "中国的埃博拉病毒是一种致命的病毒，它可以通过接触感染患者的体液或未经处理的食物传播。埃博拉病毒可以导致出血热、肠道症状、肝硬化和脑病等严重疾病，最终可能会导致死亡。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Chains**  \n",
        "-- each session will be indendent"
      ],
      "metadata": {
        "id": "mG0nIf_T08W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will create a simple chain only for a single LLM and a single task\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "BVVcxK_b1Dpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)"
      ],
      "metadata": {
        "id": "PZ1k9Chw4EHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a template for prompt object\n",
        "template = ''' You are an experienced virologist.\n",
        "Write a few sentances about the following {virus} in {language}.\n",
        "'''\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['virus', 'language'],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "HcUasxiv4fjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have llm mode and prompt object, we can create a simple chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "dh9KSf2a4vBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.run({'virus':'HSV', 'language': 'chinese'})"
      ],
      "metadata": {
        "id": "bo35Ny3Q6IA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n6UgeMz78cH",
        "outputId": "b68023b9-90ce-48d1-94aa-d9d4820d7c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSV（单纯疱疹病毒）是一种常见的病毒，可引起人类的感染。它分为HSV-1和HSV-2两种亚型，分别引起口腔和生殖部位的疱疹。HSV可以通过直接接触传播，如性接触或触摸感染部位，也可以通过唾液、体液等途径传播。HSV感染通常会引起疱疹、疼痛和发热等症状，严重感染可能导致并发症。目前，虽然没有治愈HSV的方法，但抗病毒药物可以缓解症状和减少传播风险。预防HSV感染的最佳方法是避免直接接触病毒，并保持良好的个人卫生习惯。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For single variable, then\n",
        "template = ''' You are an experienced virologist.\n",
        "Write a few sentances about the following {virus}.\n",
        "'''\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['virus'],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "AoFQ6GEd7_dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "GFKHrYp_9v73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output language will be English\n",
        "output = chain.run('HSV')\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXQygy999Elh",
        "outputId": "5abdf473-3625-4448-d71e-b8ba445c3923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSV, or Herpes Simplex Virus, is a common viral infection that affects humans. There are two types of HSV, namely HSV-1 and HSV-2. HSV-1 is primarily associated with oral herpes, causing cold sores or fever blisters around the mouth, while HSV-2 is primarily associated with genital herpes. Both types of HSV can cause painful sores or blisters on the affected area and can be transmitted through direct contact with the infected person. While there is no cure for HSV, antiviral medications can help manage the symptoms and reduce the frequency and severity of outbreaks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential Chains**"
      ],
      "metadata": {
        "id": "HDr2fLJwVyQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ],
      "metadata": {
        "id": "B5BouOA_WAJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define first LLM and put it on first member of the Chain."
      ],
      "metadata": {
        "id": "NZzXfh2lcwRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = OpenAI(model_name= 'text-davinci-003', temperature=0.7, max_tokens=1024)\n",
        "template = ''' You are an experienced scientist and Python programmer.\n",
        "Write a function that implements the conecpt of {concept}.\n",
        "'''\n",
        "prompt1 = PromptTemplate(\n",
        "    input_variables=['concept'],\n",
        "    template=template\n",
        ")\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt1)"
      ],
      "metadata": {
        "id": "YuzyeQTEZ7LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
        "prompt2 = PromptTemplate(\n",
        "    input_variables=['function'],\n",
        "    template='Given the python function {function}, describe it as detailed as possible.'\n",
        ")\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt2)"
      ],
      "metadata": {
        "id": "eAdPZfWNbe1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
        "output = all_chain.run('linear regression')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNU7QhcMeRsN",
        "outputId": "682b0664-e78d-4b23-d8c6-467a0b463c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "def linear_regression(x, y):\n",
            "    \"\"\"This function implements the concept of linear regression.\n",
            "    It takes two sets of data x and y, and returns a linear regression equation.\n",
            "    \n",
            "    Parameters:\n",
            "    x (list): The x data points\n",
            "    y (list): The y data points\n",
            "    \n",
            "    Returns:\n",
            "    equation (string): The linear regression equation\n",
            "    \"\"\"\n",
            "    \n",
            "    # Calculate the mean of x and y\n",
            "    mean_x = sum(x) / len(x)\n",
            "    mean_y = sum(y) / len(y)\n",
            "    \n",
            "    # Calculate the sum of the squared differences between x and the mean of x\n",
            "    sum_x_squared = sum([(i - mean_x)**2 for i in x])\n",
            "    \n",
            "    # Calculate the sum of the product of the differences between x and the mean of x\n",
            "    # and the differences between y and the mean of y\n",
            "    sum_xy = sum([(x[i] - mean_x) * (y[i] - mean_y) for i in range(len(x))])\n",
            "    \n",
            "    # Calculate the slope of the regression line\n",
            "    slope = sum_xy / sum_x_squared\n",
            "    \n",
            "    # Calculate the intercept of the regression line\n",
            "    intercept = mean_y - (slope * mean_x)\n",
            "    \n",
            "    # Create the linear regression equation\n",
            "    equation = \"y = {0}x + {1}\".format(slope, intercept)\n",
            "    \n",
            "    return equation\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe given Python function implements the concept of linear regression. Linear regression is a statistical approach used to study the relationship between a dependent variable `y` and one or more independent variables `x`. In this function, the user provides two sets of data points `x` and `y`, which represent the independent and dependent variables, respectively.\n",
            "\n",
            "The function starts by calculating the mean values of `x` and `y` using the `sum()` function and dividing by the length of the lists.\n",
            "\n",
            "Next, it calculates the sum of the squared differences between each element in `x` and the mean of `x`. This is done using a list comprehension that subtracts `mean_x` from each element and squares the result. The sum of these squared differences is then calculated.\n",
            "\n",
            "After that, it calculates the sum of the product of the differences between each element in `x` and the mean of `x`, and the differences between each element in `y` and the mean of `y`. This is accomplished by using a list comprehension and iterating over the indices of `x`. The differences between `x[i]` and `mean_x`, and `y[i]` and `mean_y` are multiplied together and summed.\n",
            "\n",
            "Using these calculations, the slope of the regression line is determined by dividing the sum of the products `sum_xy` by the sum of squared differences `sum_x_squared`.\n",
            "\n",
            "Next, the intercept of the regression line is computed by subtracting the product of the slope and the mean of `x` from the mean of `y`.\n",
            "\n",
            "Finally, the linear regression equation is created by formatting the slope and intercept values into a string using the `format()` method. The equation is of the form: `y = mx + b`, where `m` is the slope and `b` is the intercept.\n",
            "\n",
            "The function then returns the linear regression equation as a string.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LangChain Agents**"
      ],
      "metadata": {
        "id": "hXh4B1Do1m_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "hqkm_oX01vrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "agent_executor = create_python_agent(\n",
        "    llm = llm,\n",
        "    tool = PythonREPLTool(),\n",
        "    verbose= True\n",
        ")"
      ],
      "metadata": {
        "id": "WHY8BfGV2eNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run('Calcurate the square root of factorial 20 \\\n",
        "and display it with 4 decimal points')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "XXI_sjpM3tFp",
        "outputId": "f73e7235-4e37-4d6a-9e76-ff01d3ea6c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to calculate the square root of 20!\n",
            "Action: Python_REPL\n",
            "Action Input: from math import factorial; print(round(math.sqrt(factorial(20)), 4))\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNameError(\"name 'math' is not defined\")\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to import the math module\n",
            "Action: Python_REPL\n",
            "Action Input: import math; print(round(math.sqrt(factorial(20)), 4))\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m1559776268.6285\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 1559776268.6285\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1559776268.6285'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run('what is the answer to 5.1 ** 7.3?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "rDClsxvZ6KUp",
        "outputId": "a7e3ffd2-fc73-4e06-910d-ea412e3a0e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-oi0LtrUbPuN1r8ILRmGNwNM7 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to calculate this\n",
            "Action: Python_REPL\n",
            "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
            "\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-oi0LtrUbPuN1r8ILRmGNwNM7 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-oi0LtrUbPuN1r8ILRmGNwNM7 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-oi0LtrUbPuN1r8ILRmGNwNM7 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 146306.05007233328\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'146306.05007233328'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "5.1**7.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtkyTMzZ8E7Z",
        "outputId": "debf05ca-d488-46c5-8a33-cb298dfc98c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146306.05007233328"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFEOwF6M8G3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}